{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4",
      "authorship_tag": "ABX9TyOTzoIYEuRT9UMKXayUm1Oh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chiyeon01/CNN_Model_Mechanism/blob/main/pytorch/deepfake_tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WvuZy_Wt76GA",
        "outputId": "36aac46c-420d-4318-e544-d4fe8322f162"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (0.24.0+cu126)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: torch==2.9.0 in /usr/local/lib/python3.12/dist-packages (from torchvision) (2.9.0+cu126)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision) (11.3.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchvision) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchvision) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchvision) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchvision) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchvision) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchvision) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchvision) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchvision) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchvision) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchvision) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchvision) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchvision) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchvision) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchvision) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchvision) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchvision) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchvision) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchvision) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchvision) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchvision) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchvision) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchvision) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchvision) (3.5.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch==2.9.0->torchvision) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch==2.9.0->torchvision) (3.0.3)\n",
            "Collecting torchmetrics\n",
            "  Downloading torchmetrics-1.8.2-py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.12/dist-packages (from torchmetrics) (2.0.2)\n",
            "Requirement already satisfied: packaging>17.1 in /usr/local/lib/python3.12/dist-packages (from torchmetrics) (25.0)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from torchmetrics) (2.9.0+cu126)\n",
            "Collecting lightning-utilities>=0.8.0 (from torchmetrics)\n",
            "  Downloading lightning_utilities-0.15.2-py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (75.2.0)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.12/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.15.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (3.20.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (3.5.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.0.0->torchmetrics) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.0.0->torchmetrics) (3.0.3)\n",
            "Downloading torchmetrics-1.8.2-py3-none-any.whl (983 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m983.2/983.2 kB\u001b[0m \u001b[31m59.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lightning_utilities-0.15.2-py3-none-any.whl (29 kB)\n",
            "Installing collected packages: lightning-utilities, torchmetrics\n",
            "Successfully installed lightning-utilities-0.15.2 torchmetrics-1.8.2\n",
            "Collecting torchinfo\n",
            "  Downloading torchinfo-1.8.0-py3-none-any.whl.metadata (21 kB)\n",
            "Downloading torchinfo-1.8.0-py3-none-any.whl (23 kB)\n",
            "Installing collected packages: torchinfo\n",
            "Successfully installed torchinfo-1.8.0\n"
          ]
        }
      ],
      "source": [
        "!pip install torchvision\n",
        "!pip install torchmetrics\n",
        "!pip install torchinfo"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/chiyeon01/CNN_Model_Mechanism/refs/heads/main/pytorch/utils.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FoYNvXBH-LI9",
        "outputId": "24882953-18ea-4cd5-e936-a432a22c0d2f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-12-22 10:23:36--  https://raw.githubusercontent.com/chiyeon01/CNN_Model_Mechanism/refs/heads/main/pytorch/utils.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 10814 (11K) [text/plain]\n",
            "Saving to: ‘utils.py’\n",
            "\n",
            "utils.py            100%[===================>]  10.56K  --.-KB/s    in 0s      \n",
            "\n",
            "2025-12-22 10:23:37 (152 MB/s) - ‘utils.py’ saved [10814/10814]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Module import\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchinfo\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import models\n",
        "from torch.optim import SGD, Adagrad, RMSprop, Adam, AdamW\n",
        "import torchmetrics\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import cv2\n",
        "import os\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "from tqdm import tqdm\n",
        "from PIL import Image\n",
        "from utils import Trainer, Predictor, Custom_Dataset, create_pretrained_model"
      ],
      "metadata": {
        "id": "nt_9g2Nq8E0P"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"manjilkarki/deepfake-and-real-images\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G1D4BUi7_cEF",
        "outputId": "1336ce44-44ff-478e-f07d-931340dccdc2"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using Colab cache for faster access to the 'deepfake-and-real-images' dataset.\n",
            "Path to dataset files: /kaggle/input/deepfake-and-real-images\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Kaggle DeepFake Dataset\n",
        "image_paths = []\n",
        "labels = []\n",
        "gubuns = []\n",
        "\n",
        "for dirname, _, filenames in os.walk(\"/kaggle/input/deepfake-and-real-images\"):\n",
        "    for filename in filenames:\n",
        "        image_path = os.path.join(dirname, filename)\n",
        "        image_paths.append(image_path)\n",
        "        if 'Train' in image_path:\n",
        "            gubuns.append('Train')\n",
        "        elif 'Validation' in image_path:\n",
        "            gubuns.append('Validation')\n",
        "        elif 'Test' in image_path:\n",
        "            gubuns.append('Test')\n",
        "\n",
        "        if 'Real' in image_path:\n",
        "            labels.append('Real')\n",
        "        elif 'Fake' in image_path:\n",
        "            labels.append('Fake')\n",
        "\n",
        "print(f\"학습 데이터 수: {len(image_paths)}\")\n",
        "print(f\"타겟 수: {len(labels)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s_scFDyrPYlB",
        "outputId": "257e377e-d774-4b96-bb89-872d63766f2c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "학습 데이터 수: 190335\n",
            "타겟 수: 190335\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train, Validation, Test 모두를 담는 DataFrame\n",
        "deepfake_df = pd.DataFrame({\n",
        "    'image_path': image_paths,\n",
        "    'label': labels,\n",
        "    'gubun': gubuns\n",
        "})\n",
        "deepfake_df['label'] = deepfake_df['label'].map({\n",
        "    'Real': 0,\n",
        "    'Fake': 1\n",
        "})\n",
        "\n",
        "# Train DataFrame\n",
        "train_df = deepfake_df[deepfake_df['gubun'] == 'Train']\n",
        "\n",
        "# Validation DataFrame\n",
        "val_df = deepfake_df[deepfake_df['gubun'] == 'Validation']\n",
        "\n",
        "# Test DataFrame\n",
        "test_df = deepfake_df[deepfake_df['gubun'] == 'Test']\n",
        "\n",
        "print(f\"Train DataFrame Shape: {train_df.shape}\")\n",
        "print(f\"Validation DataFrame Shape: {val_df.shape}\")\n",
        "print(f\"Test DataFrame Shape: {test_df.shape}\")\n",
        "print(f\"All DataFrame Shape: {deepfake_df.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LTkbsAD3R-Fb",
        "outputId": "7b1d08a7-eaae-405d-9b99-0adcafa2634a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train DataFrame Shape: (140002, 3)\n",
            "Validation DataFrame Shape: (39428, 3)\n",
            "Test DataFrame Shape: (10905, 3)\n",
            "All DataFrame Shape: (190335, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Config & Settings\n",
        "class Config:\n",
        "    batch_size = 32\n",
        "    FineTune = False\n",
        "    shuffle = False\n",
        "    first_learning_rate = 1e-3\n",
        "    second_learning_rate = 1e-4\n",
        "    image_size = [224, 224] # 이미지는 3채널로 간주(image is 3 channels)\n",
        "    model_name = 'efficientnet_b0'\n",
        "    make_summary = False\n",
        "    callbacks = []\n",
        "    metric = torchmetrics.classification.Accuracy(task=\"multiclass\", num_classes=10)\n",
        "    classifier_layer = nn.Sequential(\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(in_features=1280, out_features=2)\n",
        "        )"
      ],
      "metadata": {
        "id": "XteSgbSY9y4V"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 생성\n",
        "model = create_pretrained_model(\n",
        "    model_name = Config.model_name,\n",
        "    classifier_layer = Config.classifier_layer,\n",
        "    image_size=Config.image_size,\n",
        "    make_summary = Config.make_summary\n",
        ")\n",
        "\n",
        "# albumentation 기반 transform 생성.\n",
        "transform = A.Compose([\n",
        "    A.Resize(*Config.image_size),\n",
        "    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
        "    ToTensorV2()\n",
        "])\n",
        "\n",
        "# dataset 생성\n",
        "train_dataset = Custom_Dataset(train_df['image_path'].values, targets=train_df['label'].values, transform=transform)\n",
        "val_dataset = Custom_Dataset(val_df['image_path'].values, targets=val_df['label'].values, transform=transform)\n",
        "test_dataset = Custom_Dataset(test_df['image_path'].values, targets=test_df['label'].values, transform=transform)\n",
        "\n",
        "# dataloader 생성\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True, pin_memory=True)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=16, shuffle=False, pin_memory=True)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=16, shuffle=False, pin_memory=True)\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = Adam(model.parameters(), lr=Config.first_learning_rate)\n",
        "\n",
        "trainer = Trainer(model=model, loss_fn=loss_fn, metric=Config.metric, optimizer=optimizer)\n",
        "\n",
        "history = trainer.fit(epochs=1, train_dataloader=train_dataloader, val_dataloader=val_dataloader)"
      ],
      "metadata": {
        "id": "dmla9g1d-RNp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d6c964a0-6d5a-4e51-a081-a08b13366825"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/efficientnet_b0_rwightman-7f5810bc.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet_b0_rwightman-7f5810bc.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20.5M/20.5M [00:00<00:00, 231MB/s]\n",
            "[Training...] : 100%|██████████| 8751/8751 [16:56<00:00,  8.61it/s, Train_Loss=0.0863, Train_Accuracy=0.5]\n",
            "[Validating..] : 100%|██████████| 2465/2465 [03:38<00:00, 11.29it/s, Validate_Loss=0.0805, Validate_Accuracy=1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate\n",
        "trainer.evaluate(test_dataloader)"
      ],
      "metadata": {
        "id": "Gs9sfLQiWS4e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86eda3e9-9f42-4f8c-d49a-ee8cda65aecf"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Evaluating..] : 100%|██████████| 682/682 [01:02<00:00, 10.93it/s, Evaluate_Loss=0.21, Evaluate_Accuracy=0.889]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.21004895801393758, 0.8888888955116272)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# return trained model\n",
        "model = trainer.get_trained_model()"
      ],
      "metadata": {
        "id": "oWRg2YVHjQbX"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model save\n",
        "torch.save(model.state_dict(), \"model_weights.pt\")"
      ],
      "metadata": {
        "id": "WA8vwkQclkQT"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model load\n",
        "model = create_pretrained_model(\n",
        "    model_name = Config.model_name,\n",
        "    classifier_layer = Config.classifier_layer,\n",
        "    image_size=Config.image_size,\n",
        "    make_summary = Config.make_summary\n",
        ")\n",
        "\n",
        "model.load_state_dict(torch.load(\"model_weights.pt\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EmdyOErTl4uD",
        "outputId": "9642e439-2dc1-4047-95f8-e829681a70ac"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g9DFRK85rd63",
        "outputId": "4c0cf777-0d35-4b7d-9e63-f2e0f1849e12"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "EfficientNet(\n",
              "  (features): Sequential(\n",
              "    (0): Conv2dNormActivation(\n",
              "      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): SiLU(inplace=True)\n",
              "    )\n",
              "    (1): Sequential(\n",
              "      (0): MBConv(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2dNormActivation(\n",
              "            (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
              "            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (1): SqueezeExcitation(\n",
              "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "            (fc1): Conv2d(32, 8, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (fc2): Conv2d(8, 32, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (activation): SiLU(inplace=True)\n",
              "            (scale_activation): Sigmoid()\n",
              "          )\n",
              "          (2): Conv2dNormActivation(\n",
              "            (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (stochastic_depth): StochasticDepth(p=0.0, mode=row)\n",
              "      )\n",
              "    )\n",
              "    (2): Sequential(\n",
              "      (0): MBConv(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2dNormActivation(\n",
              "            (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (1): Conv2dNormActivation(\n",
              "            (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
              "            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (2): SqueezeExcitation(\n",
              "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "            (fc1): Conv2d(96, 4, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (fc2): Conv2d(4, 96, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (activation): SiLU(inplace=True)\n",
              "            (scale_activation): Sigmoid()\n",
              "          )\n",
              "          (3): Conv2dNormActivation(\n",
              "            (0): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (stochastic_depth): StochasticDepth(p=0.0125, mode=row)\n",
              "      )\n",
              "      (1): MBConv(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2dNormActivation(\n",
              "            (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (1): Conv2dNormActivation(\n",
              "            (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
              "            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (2): SqueezeExcitation(\n",
              "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "            (fc1): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (fc2): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (activation): SiLU(inplace=True)\n",
              "            (scale_activation): Sigmoid()\n",
              "          )\n",
              "          (3): Conv2dNormActivation(\n",
              "            (0): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (stochastic_depth): StochasticDepth(p=0.025, mode=row)\n",
              "      )\n",
              "    )\n",
              "    (3): Sequential(\n",
              "      (0): MBConv(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2dNormActivation(\n",
              "            (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (1): Conv2dNormActivation(\n",
              "            (0): Conv2d(144, 144, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=144, bias=False)\n",
              "            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (2): SqueezeExcitation(\n",
              "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "            (fc1): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (fc2): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (activation): SiLU(inplace=True)\n",
              "            (scale_activation): Sigmoid()\n",
              "          )\n",
              "          (3): Conv2dNormActivation(\n",
              "            (0): Conv2d(144, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (stochastic_depth): StochasticDepth(p=0.037500000000000006, mode=row)\n",
              "      )\n",
              "      (1): MBConv(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2dNormActivation(\n",
              "            (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (1): Conv2dNormActivation(\n",
              "            (0): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)\n",
              "            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (2): SqueezeExcitation(\n",
              "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "            (fc1): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (fc2): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (activation): SiLU(inplace=True)\n",
              "            (scale_activation): Sigmoid()\n",
              "          )\n",
              "          (3): Conv2dNormActivation(\n",
              "            (0): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (stochastic_depth): StochasticDepth(p=0.05, mode=row)\n",
              "      )\n",
              "    )\n",
              "    (4): Sequential(\n",
              "      (0): MBConv(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2dNormActivation(\n",
              "            (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (1): Conv2dNormActivation(\n",
              "            (0): Conv2d(240, 240, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=240, bias=False)\n",
              "            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (2): SqueezeExcitation(\n",
              "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "            (fc1): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (fc2): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (activation): SiLU(inplace=True)\n",
              "            (scale_activation): Sigmoid()\n",
              "          )\n",
              "          (3): Conv2dNormActivation(\n",
              "            (0): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (stochastic_depth): StochasticDepth(p=0.0625, mode=row)\n",
              "      )\n",
              "      (1): MBConv(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2dNormActivation(\n",
              "            (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (1): Conv2dNormActivation(\n",
              "            (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
              "            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (2): SqueezeExcitation(\n",
              "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "            (fc1): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (fc2): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (activation): SiLU(inplace=True)\n",
              "            (scale_activation): Sigmoid()\n",
              "          )\n",
              "          (3): Conv2dNormActivation(\n",
              "            (0): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (stochastic_depth): StochasticDepth(p=0.07500000000000001, mode=row)\n",
              "      )\n",
              "      (2): MBConv(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2dNormActivation(\n",
              "            (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (1): Conv2dNormActivation(\n",
              "            (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
              "            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (2): SqueezeExcitation(\n",
              "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "            (fc1): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (fc2): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (activation): SiLU(inplace=True)\n",
              "            (scale_activation): Sigmoid()\n",
              "          )\n",
              "          (3): Conv2dNormActivation(\n",
              "            (0): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (stochastic_depth): StochasticDepth(p=0.08750000000000001, mode=row)\n",
              "      )\n",
              "    )\n",
              "    (5): Sequential(\n",
              "      (0): MBConv(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2dNormActivation(\n",
              "            (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (1): Conv2dNormActivation(\n",
              "            (0): Conv2d(480, 480, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=480, bias=False)\n",
              "            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (2): SqueezeExcitation(\n",
              "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "            (fc1): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (fc2): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (activation): SiLU(inplace=True)\n",
              "            (scale_activation): Sigmoid()\n",
              "          )\n",
              "          (3): Conv2dNormActivation(\n",
              "            (0): Conv2d(480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (stochastic_depth): StochasticDepth(p=0.1, mode=row)\n",
              "      )\n",
              "      (1): MBConv(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2dNormActivation(\n",
              "            (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (1): Conv2dNormActivation(\n",
              "            (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
              "            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (2): SqueezeExcitation(\n",
              "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "            (fc1): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (fc2): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (activation): SiLU(inplace=True)\n",
              "            (scale_activation): Sigmoid()\n",
              "          )\n",
              "          (3): Conv2dNormActivation(\n",
              "            (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (stochastic_depth): StochasticDepth(p=0.1125, mode=row)\n",
              "      )\n",
              "      (2): MBConv(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2dNormActivation(\n",
              "            (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (1): Conv2dNormActivation(\n",
              "            (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
              "            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (2): SqueezeExcitation(\n",
              "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "            (fc1): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (fc2): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (activation): SiLU(inplace=True)\n",
              "            (scale_activation): Sigmoid()\n",
              "          )\n",
              "          (3): Conv2dNormActivation(\n",
              "            (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (stochastic_depth): StochasticDepth(p=0.125, mode=row)\n",
              "      )\n",
              "    )\n",
              "    (6): Sequential(\n",
              "      (0): MBConv(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2dNormActivation(\n",
              "            (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (1): Conv2dNormActivation(\n",
              "            (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=672, bias=False)\n",
              "            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (2): SqueezeExcitation(\n",
              "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "            (fc1): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (fc2): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (activation): SiLU(inplace=True)\n",
              "            (scale_activation): Sigmoid()\n",
              "          )\n",
              "          (3): Conv2dNormActivation(\n",
              "            (0): Conv2d(672, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (stochastic_depth): StochasticDepth(p=0.1375, mode=row)\n",
              "      )\n",
              "      (1): MBConv(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2dNormActivation(\n",
              "            (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (1): Conv2dNormActivation(\n",
              "            (0): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
              "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (2): SqueezeExcitation(\n",
              "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "            (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (activation): SiLU(inplace=True)\n",
              "            (scale_activation): Sigmoid()\n",
              "          )\n",
              "          (3): Conv2dNormActivation(\n",
              "            (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (stochastic_depth): StochasticDepth(p=0.15000000000000002, mode=row)\n",
              "      )\n",
              "      (2): MBConv(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2dNormActivation(\n",
              "            (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (1): Conv2dNormActivation(\n",
              "            (0): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
              "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (2): SqueezeExcitation(\n",
              "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "            (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (activation): SiLU(inplace=True)\n",
              "            (scale_activation): Sigmoid()\n",
              "          )\n",
              "          (3): Conv2dNormActivation(\n",
              "            (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (stochastic_depth): StochasticDepth(p=0.1625, mode=row)\n",
              "      )\n",
              "      (3): MBConv(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2dNormActivation(\n",
              "            (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (1): Conv2dNormActivation(\n",
              "            (0): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
              "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (2): SqueezeExcitation(\n",
              "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "            (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (activation): SiLU(inplace=True)\n",
              "            (scale_activation): Sigmoid()\n",
              "          )\n",
              "          (3): Conv2dNormActivation(\n",
              "            (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (stochastic_depth): StochasticDepth(p=0.17500000000000002, mode=row)\n",
              "      )\n",
              "    )\n",
              "    (7): Sequential(\n",
              "      (0): MBConv(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2dNormActivation(\n",
              "            (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (1): Conv2dNormActivation(\n",
              "            (0): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
              "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (2): SqueezeExcitation(\n",
              "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "            (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (activation): SiLU(inplace=True)\n",
              "            (scale_activation): Sigmoid()\n",
              "          )\n",
              "          (3): Conv2dNormActivation(\n",
              "            (0): Conv2d(1152, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (stochastic_depth): StochasticDepth(p=0.1875, mode=row)\n",
              "      )\n",
              "    )\n",
              "    (8): Conv2dNormActivation(\n",
              "      (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): SiLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "  (classifier): Sequential(\n",
              "    (0): Dropout(p=0.2, inplace=False)\n",
              "    (1): Linear(in_features=1280, out_features=2, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "l0_7t0xosH5W"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}