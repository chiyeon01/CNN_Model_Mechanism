{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4",
      "authorship_tag": "ABX9TyOCHTwgYUIhF9zlqlYS3AyR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chiyeon01/CNN_Model_Mechanism/blob/main/pytorch/deepfake_tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 이 튜토리얼은 딥페이크 영상과 이미지 데이터셋을 기반으로 모델을 훈련합니다."
      ],
      "metadata": {
        "id": "aYjWQw0RvwIJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WvuZy_Wt76GA",
        "outputId": "33574816-1dd5-4ff3-fa6d-0dfb4ad20d80"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (0.24.0+cu126)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: torch==2.9.0 in /usr/local/lib/python3.12/dist-packages (from torchvision) (2.9.0+cu126)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision) (11.3.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchvision) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchvision) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchvision) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchvision) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchvision) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchvision) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchvision) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchvision) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchvision) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchvision) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchvision) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchvision) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchvision) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchvision) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchvision) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchvision) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchvision) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchvision) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchvision) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchvision) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchvision) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchvision) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchvision) (3.5.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch==2.9.0->torchvision) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch==2.9.0->torchvision) (3.0.3)\n",
            "Collecting torchmetrics\n",
            "  Downloading torchmetrics-1.8.2-py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.12/dist-packages (from torchmetrics) (2.0.2)\n",
            "Requirement already satisfied: packaging>17.1 in /usr/local/lib/python3.12/dist-packages (from torchmetrics) (25.0)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from torchmetrics) (2.9.0+cu126)\n",
            "Collecting lightning-utilities>=0.8.0 (from torchmetrics)\n",
            "  Downloading lightning_utilities-0.15.2-py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (75.2.0)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.12/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.15.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (3.20.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (3.5.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.0.0->torchmetrics) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.0.0->torchmetrics) (3.0.3)\n",
            "Downloading torchmetrics-1.8.2-py3-none-any.whl (983 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m983.2/983.2 kB\u001b[0m \u001b[31m55.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lightning_utilities-0.15.2-py3-none-any.whl (29 kB)\n",
            "Installing collected packages: lightning-utilities, torchmetrics\n",
            "Successfully installed lightning-utilities-0.15.2 torchmetrics-1.8.2\n",
            "Collecting torchinfo\n",
            "  Downloading torchinfo-1.8.0-py3-none-any.whl.metadata (21 kB)\n",
            "Downloading torchinfo-1.8.0-py3-none-any.whl (23 kB)\n",
            "Installing collected packages: torchinfo\n",
            "Successfully installed torchinfo-1.8.0\n"
          ]
        }
      ],
      "source": [
        "!pip install torchvision\n",
        "!pip install torchmetrics\n",
        "!pip install torchinfo"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/chiyeon01/CNN_Model_Mechanism/refs/heads/main/pytorch/utils.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FoYNvXBH-LI9",
        "outputId": "24882953-18ea-4cd5-e936-a432a22c0d2f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-12-22 10:23:36--  https://raw.githubusercontent.com/chiyeon01/CNN_Model_Mechanism/refs/heads/main/pytorch/utils.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 10814 (11K) [text/plain]\n",
            "Saving to: ‘utils.py’\n",
            "\n",
            "utils.py            100%[===================>]  10.56K  --.-KB/s    in 0s      \n",
            "\n",
            "2025-12-22 10:23:37 (152 MB/s) - ‘utils.py’ saved [10814/10814]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train"
      ],
      "metadata": {
        "id": "oQ_JP7eLhaEq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Module import\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchinfo\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import models\n",
        "from torch.optim import SGD, Adagrad, RMSprop, Adam, AdamW\n",
        "import torchmetrics\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import cv2\n",
        "import os\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "from tqdm import tqdm\n",
        "from PIL import Image\n",
        "from utils import Trainer, Predictor, Custom_Dataset, create_pretrained_model, video2images"
      ],
      "metadata": {
        "id": "nt_9g2Nq8E0P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"manjilkarki/deepfake-and-real-images\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G1D4BUi7_cEF",
        "outputId": "1336ce44-44ff-478e-f07d-931340dccdc2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using Colab cache for faster access to the 'deepfake-and-real-images' dataset.\n",
            "Path to dataset files: /kaggle/input/deepfake-and-real-images\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Kaggle DeepFake Dataset\n",
        "image_paths = []\n",
        "video_paths = []\n",
        "labels = []\n",
        "gubuns = []\n",
        "\n",
        "for dirname, _, filenames in os.walk(\"/kaggle/input/deepfake-and-real-images\"):\n",
        "    for filename in filenames:\n",
        "        path = os.path.join(dirname, filename)\n",
        "        if '.mp4' in path or '.mov' in path:\n",
        "            # video인 경우 이후 처리를 위해 따로 경로 저장\n",
        "            video_paths.append(path)\n",
        "\n",
        "            # video인 경우 image 경로 생성 후 경로 반환\n",
        "            image_file_paths = video2images(video_file_paths=[path], save_dirname=dirname)\n",
        "            image_paths.append(*image_file_paths)\n",
        "\n",
        "            # 각 video의 모든 프레임을 gubuns에 append\n",
        "            if 'Train' in path:\n",
        "                for _ in image_file_paths:\n",
        "                    gubuns.append('Train')\n",
        "            elif 'Validation' in path:\n",
        "                for _ in image_file_paths:\n",
        "                    gubuns.append('Validation')\n",
        "            elif 'Test' in path:\n",
        "                for _ in image_file_paths:\n",
        "                    gubuns.append('Test')\n",
        "\n",
        "            if 'Real' in path:\n",
        "                for _ in image_file_paths:\n",
        "                    labels.append('Real')\n",
        "            elif 'Fake' in path:\n",
        "                for _ in image_file_paths:\n",
        "                    labels.append('Fake')\n",
        "\n",
        "        else: # image인 경우 그대로\n",
        "            image_paths.append(path)\n",
        "            if 'Train' in path:\n",
        "                gubuns.append('Train')\n",
        "            elif 'Validation' in path:\n",
        "                gubuns.append('Validation')\n",
        "            elif 'Test' in path:\n",
        "                gubuns.append('Test')\n",
        "\n",
        "            if 'Real' in path:\n",
        "                labels.append('Real')\n",
        "            elif 'Fake' in path:\n",
        "                labels.append('Fake')\n",
        "\n",
        "print(f\"학습 데이터 수: {len(image_paths)}\")\n",
        "print(f\"타겟 수: {len(labels)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s_scFDyrPYlB",
        "outputId": "257e377e-d774-4b96-bb89-872d63766f2c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "학습 데이터 수: 190335\n",
            "타겟 수: 190335\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train, Validation, Test 모두를 담는 DataFrame\n",
        "deepfake_df = pd.DataFrame({\n",
        "    'image_path': image_paths,\n",
        "    'label': labels,\n",
        "    'gubun': gubuns\n",
        "})\n",
        "deepfake_df['label'] = deepfake_df['label'].map({\n",
        "    'Real': 0,\n",
        "    'Fake': 1\n",
        "})\n",
        "\n",
        "# Train DataFrame\n",
        "train_df = deepfake_df[deepfake_df['gubun'] == 'Train']\n",
        "\n",
        "# Validation DataFrame\n",
        "val_df = deepfake_df[deepfake_df['gubun'] == 'Validation']\n",
        "\n",
        "# Test DataFrame\n",
        "test_df = deepfake_df[deepfake_df['gubun'] == 'Test']\n",
        "\n",
        "print(f\"Train DataFrame Shape: {train_df.shape}\")\n",
        "print(f\"Validation DataFrame Shape: {val_df.shape}\")\n",
        "print(f\"Test DataFrame Shape: {test_df.shape}\")\n",
        "print(f\"All DataFrame Shape: {deepfake_df.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LTkbsAD3R-Fb",
        "outputId": "7b1d08a7-eaae-405d-9b99-0adcafa2634a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train DataFrame Shape: (140002, 3)\n",
            "Validation DataFrame Shape: (39428, 3)\n",
            "Test DataFrame Shape: (10905, 3)\n",
            "All DataFrame Shape: (190335, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Config & Settings\n",
        "class Config:\n",
        "    batch_size = 32\n",
        "    FineTune = False\n",
        "    shuffle = False\n",
        "    first_learning_rate = 1e-3\n",
        "    second_learning_rate = 1e-4\n",
        "    image_size = [224, 224] # 이미지는 3채널로 간주(image is 3 channels)\n",
        "    model_name = 'efficientnet_b0'\n",
        "    make_summary = False\n",
        "    callbacks = []\n",
        "    metric = torchmetrics.classification.Accuracy(task=\"multiclass\", num_classes=10)\n",
        "    classifier_layer = nn.Sequential(\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(in_features=1280, out_features=2)\n",
        "        )"
      ],
      "metadata": {
        "id": "XteSgbSY9y4V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 생성\n",
        "model = create_pretrained_model(\n",
        "    model_name = Config.model_name,\n",
        "    classifier_layer = Config.classifier_layer,\n",
        "    image_size=Config.image_size,\n",
        "    make_summary = Config.make_summary\n",
        ")\n",
        "\n",
        "# albumentation 기반 transform 생성.\n",
        "transform = A.Compose([\n",
        "    A.Resize(*Config.image_size),\n",
        "    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
        "    ToTensorV2()\n",
        "])\n",
        "\n",
        "# dataset 생성\n",
        "train_dataset = Custom_Dataset(train_df['image_path'].values, targets=train_df['label'].values, transform=transform)\n",
        "val_dataset = Custom_Dataset(val_df['image_path'].values, targets=val_df['label'].values, transform=transform)\n",
        "test_dataset = Custom_Dataset(test_df['image_path'].values, targets=test_df['label'].values, transform=transform)\n",
        "\n",
        "# dataloader 생성\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True, pin_memory=True)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=16, shuffle=False, pin_memory=True)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=16, shuffle=False, pin_memory=True)\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = Adam(model.parameters(), lr=Config.first_learning_rate)\n",
        "\n",
        "trainer = Trainer(model=model, loss_fn=loss_fn, metric=Config.metric, optimizer=optimizer)\n",
        "\n",
        "history = trainer.fit(epochs=1, train_dataloader=train_dataloader, val_dataloader=val_dataloader)"
      ],
      "metadata": {
        "id": "dmla9g1d-RNp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d6c964a0-6d5a-4e51-a081-a08b13366825"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/efficientnet_b0_rwightman-7f5810bc.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet_b0_rwightman-7f5810bc.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20.5M/20.5M [00:00<00:00, 231MB/s]\n",
            "[Training...] : 100%|██████████| 8751/8751 [16:56<00:00,  8.61it/s, Train_Loss=0.0863, Train_Accuracy=0.5]\n",
            "[Validating..] : 100%|██████████| 2465/2465 [03:38<00:00, 11.29it/s, Validate_Loss=0.0805, Validate_Accuracy=1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate\n",
        "trainer.evaluate(test_dataloader)"
      ],
      "metadata": {
        "id": "Gs9sfLQiWS4e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86eda3e9-9f42-4f8c-d49a-ee8cda65aecf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Evaluating..] : 100%|██████████| 682/682 [01:02<00:00, 10.93it/s, Evaluate_Loss=0.21, Evaluate_Accuracy=0.889]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.21004895801393758, 0.8888888955116272)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# return trained model\n",
        "model = trainer.get_trained_model()"
      ],
      "metadata": {
        "id": "oWRg2YVHjQbX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model save\n",
        "torch.save(model.state_dict(), \"model_weights.pt\")"
      ],
      "metadata": {
        "id": "WA8vwkQclkQT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model load\n",
        "model = create_pretrained_model(\n",
        "    model_name = Config.model_name,\n",
        "    classifier_layer = Config.classifier_layer,\n",
        "    image_size=Config.image_size,\n",
        "    make_summary = Config.make_summary\n",
        ")\n",
        "\n",
        "model.load_state_dict(torch.load(\"model_weights.pt\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EmdyOErTl4uD",
        "outputId": "9642e439-2dc1-4047-95f8-e829681a70ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Predict"
      ],
      "metadata": {
        "id": "9RAqUu2RheIU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Predictor 객체 선언\n",
        "predictor = Predictor(model)\n",
        "\n",
        "predictor.predict(test_dataloader)"
      ],
      "metadata": {
        "id": "l0_7t0xosH5W"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}